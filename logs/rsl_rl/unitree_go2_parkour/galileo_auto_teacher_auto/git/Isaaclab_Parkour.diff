--- git status ---
On branch master
Your branch is up to date with 'origin/master'.

Changes not staged for commit:
  (use "git add <file>..." to update what will be committed)
  (use "git restore <file>..." to discard changes in working directory)
	modified:   README.md
	modified:   parkour_isaaclab/envs/mdp/__pycache__/rewards.cpython-311.pyc
	modified:   parkour_isaaclab/envs/mdp/rewards.py
	modified:   parkour_tasks/parkour_tasks/extreme_parkour_task/config/galileo/__pycache__/parkour_teacher_cfg.cpython-311.pyc
	modified:   parkour_tasks/parkour_tasks/extreme_parkour_task/config/galileo/parkour_teacher_cfg.py

Untracked files:
  (use "git add <file>..." to include in what will be committed)
	logs/
	outputs/2025-11-24/

no changes added to commit (use "git add" and/or "git commit -a") 


--- git diff ---
diff --git a/README.md b/README.md
index 0718fab..70786e8 100644
--- a/README.md
+++ b/README.md
@@ -32,19 +32,19 @@ pip install --no-build-isolation -e .         # 避免网络获取；toml 文件
 ```bash
 cd /home/lz/Project/IsaacLab/Isaaclab_Parkour
 LOG_RUN_NAME=galileo_auto_teacher python scripts/rsl_rl/train.py \
-  --task parkour_tasks/extreme_parkour_task/config/galileo/parkour_teacher_cfg.py \
-  --num_envs 4096 --max_iterations 50000 --run_name auto
+  --task Isaac-Galileo-Parkour-Teacher-v0 \
+  --num_envs 4096 --max_iterations 50000 --run_name auto --headless
 
 LOG_RUN_NAME=galileo_auto_student python scripts/rsl_rl/train.py \
-  --task parkour_tasks/extreme_parkour_task/config/galileo/parkour_student_cfg.py \
-  --num_envs 2048 --max_iterations 50000 --run_name auto
+  --task Isaac-Galileo-Parkour-Student-v0 \
+  --num_envs 2048 --max_iterations 50000 --run_name auto --headless
 ```
 
 **多卡分布式（4 卡示例）**
 ```bash
 cd /home/lz/Project/IsaacLab/Isaaclab_Parkour
 torchrun --nproc_per_node=4 scripts/rsl_rl/train.py \
-  --task parkour_tasks/extreme_parkour_task/config/galileo/parkour_teacher_cfg.py \
+  --task Isaac-Galileo-Parkour-Teacher-v0 \
   --distributed --num_envs 4096 --max_iterations 50000 \
   --run_name auto --device cuda:0
 ```
@@ -54,11 +54,12 @@ torchrun --nproc_per_node=4 scripts/rsl_rl/train.py \
 **Play 可视化**
 ```bash
 python scripts/rsl_rl/play.py \
-  --task parkour_tasks/extreme_parkour_task/config/galileo/parkour_teacher_cfg.py \
+  --task Isaac-Galileo-Parkour-Teacher-Play-v0 \
   --checkpoint logs/rsl_rl/<exp>/<run>/checkpoints/ckpt_<iter>.pt \
   --num_envs 16 --video_length 500
 ```
 - Play 默认 `layout="competition"` 展示 20/30/40/50 固定栏杆；可在 cfg 中切换为 `fixed`（5/10/20/30/40/50 档）或 `auto` 复现训练逻辑。
+- `--task` 参数需要使用已注册的 Gym 环境名（例如 `Isaac-Galileo-Parkour-Teacher-v0`），不要传入 cfg 文件路径；可运行 `python list_envs.py` 查看当前可用的环境 ID。
 
 ## 运行策略的方法
 
diff --git a/parkour_isaaclab/envs/mdp/__pycache__/rewards.cpython-311.pyc b/parkour_isaaclab/envs/mdp/__pycache__/rewards.cpython-311.pyc
index 9c73550..c1f20b3 100644
Binary files a/parkour_isaaclab/envs/mdp/__pycache__/rewards.cpython-311.pyc and b/parkour_isaaclab/envs/mdp/__pycache__/rewards.cpython-311.pyc differ
diff --git a/parkour_isaaclab/envs/mdp/rewards.py b/parkour_isaaclab/envs/mdp/rewards.py
index 63b9955..d76f417 100644
--- a/parkour_isaaclab/envs/mdp/rewards.py
+++ b/parkour_isaaclab/envs/mdp/rewards.py
@@ -243,7 +243,8 @@ def reward_jump_clearance(env: ParkourManagerBasedRLEnv, asset_cfg: SceneEntityC
     ground_z = env.scene.env_origins[:, 2:3]
     height_scale = torch.clamp((nearest_hurdle_z - ground_z) / 0.5, 0.3, 1.5)
     foot_reward = torch.where(close_mask, clearance, torch.zeros_like(clearance))
-    return (foot_reward.mean(dim=1) * height_scale.squeeze(1)) * (terrain_types < 2)
+    # 按每只脚的栏杆高度加权后再取平均，避免维度不匹配
+    return (foot_reward * height_scale).mean(dim=1) * (terrain_types < 2)
 
 def reward_tracking_yaw(     
     env: ParkourManagerBasedRLEnv, 
diff --git a/parkour_tasks/parkour_tasks/extreme_parkour_task/config/galileo/__pycache__/parkour_teacher_cfg.cpython-311.pyc b/parkour_tasks/parkour_tasks/extreme_parkour_task/config/galileo/__pycache__/parkour_teacher_cfg.cpython-311.pyc
index c3cfbef..a302396 100644
Binary files a/parkour_tasks/parkour_tasks/extreme_parkour_task/config/galileo/__pycache__/parkour_teacher_cfg.cpython-311.pyc and b/parkour_tasks/parkour_tasks/extreme_parkour_task/config/galileo/__pycache__/parkour_teacher_cfg.cpython-311.pyc differ
diff --git a/parkour_tasks/parkour_tasks/extreme_parkour_task/config/galileo/parkour_teacher_cfg.py b/parkour_tasks/parkour_tasks/extreme_parkour_task/config/galileo/parkour_teacher_cfg.py
index cfa1683..6a8313c 100644
--- a/parkour_tasks/parkour_tasks/extreme_parkour_task/config/galileo/parkour_teacher_cfg.py
+++ b/parkour_tasks/parkour_tasks/extreme_parkour_task/config/galileo/parkour_teacher_cfg.py
@@ -113,6 +113,9 @@ def place_galileo_hurdles(
         else:
             layout_mode = "jump_train"
 
+    # 统一的栏杆高度增量（米），供各布局模式复用
+    increments = torch.tensor([0.00, 0.05, 0.10, 0.15], device=env.device)
+
     # 固定比赛布局：直接使用 20/30/40/50cm 四根栏杆（有序递增）
     if layout_mode == "competition":
         num_visible = torch.full_like(terrain_levels, 4)
@@ -157,7 +160,6 @@ def place_galileo_hurdles(
     base_heights[jump_mask] = 0.05 + 0.30 * difficulty[jump_mask]  # 5cm -> 35cm
     base_heights[crawl_mask] = 0.60 - 0.25 * difficulty[crawl_mask]  # 60cm -> 35cm
 
-    increments = torch.tensor([0.00, 0.05, 0.10, 0.15], device=env.device)
     target_x = env_origins[:, 0].unsqueeze(1) + start + spacing * torch.arange(4, device=env.device)
     target_y = env_origins[:, 1].unsqueeze(1)
     # 目标高度矩阵 shape (num_envs, 4)（仅用于选择最接近的资产）